{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f8b31e-9997-4b8c-9ce8-bdca2b38b526",
   "metadata": {},
   "source": [
    "# $\\alpha(k)$ likelihood components \n",
    "\n",
    "This notebook accompanies the paper **‚ÄúGoing beyond $S_8$: fast inference of the matter power spectrum from weak-lensing surveys‚Äù** and extracts components to write a likelihood based on the $\\alpha(k)$ posteriors obtained in the main results. Please refer to the main Jupyter notebook for a step-by-step guide to reproduce the analysis. \n",
    "\n",
    "### üîç What this notebook does\n",
    "Extracts the necessary components for an $\\alpha(k)$ likelihood to run using `MontePython`. Specifically, from the $\\alpha(k)$ posteriors, we want \n",
    "- $k$ vector \n",
    "- $\\alpha(k)$ means \n",
    "- covariance martix in $\\alpha(k)$ space \n",
    "\n",
    "Additionally, we also store \n",
    "- the effective redshift $z_{\\rm eff}$ probed by the experiment or combination of experiments \n",
    "- the fiducial cosmology to compare to, stored as the nonlinear matter power spectrum $P(k, z_{\\rm eff})$ at the $k$ vector above and the effective redshift $z_{\\rm eff}$ \n",
    "\n",
    "These are then written to an `npz` output file that is read by `MontePython`. \n",
    "\n",
    "### üõ† Requirements\n",
    "This notebook uses:\n",
    "- `numpy`\n",
    "- `pyccl` for cosmological computations\n",
    "\n",
    "### üìÇ Folder structure\n",
    "- `data/`: holds data products called by MP. Copy contents of directory into `montepython_public/data`\n",
    "- `likelihoods/`: holds cls2pk MP likelihood. Copy contents of directory into `montepython_public/montepython/likelihoods`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19b868c-f8c2-47d2-be9f-a29c873fcfa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T17:31:27.844404Z",
     "iopub.status.busy": "2025-05-14T17:31:27.843871Z",
     "iopub.status.idle": "2025-05-14T17:31:33.108443Z",
     "shell.execute_reply": "2025-05-14T17:31:33.103829Z",
     "shell.execute_reply.started": "2025-05-14T17:31:27.844376Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyccl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9565498-f28e-47dc-8293-9b13f950708b",
   "metadata": {},
   "source": [
    "### $k,z$ values \n",
    "\n",
    "Per the paper, we use 24 logarithmic bins between $10^{-3}$ and $10^2{\\rm Mpc}^{-1}$ and refer to Table 1 for the effective redshifts for each experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbe778f-8874-4282-8393-cb14f07fd430",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T17:31:33.176191Z",
     "iopub.status.busy": "2025-05-14T17:31:33.175984Z",
     "iopub.status.idle": "2025-05-14T17:31:33.185867Z",
     "shell.execute_reply": "2025-05-14T17:31:33.185186Z",
     "shell.execute_reply.started": "2025-05-14T17:31:33.176172Z"
    }
   },
   "outputs": [],
   "source": [
    "# logk bins\n",
    "nk = 24\n",
    "kk_edges = np.logspace(-3, 2, nk + 1)\n",
    "kk = np.exp(0.5 * (np.log(kk_edges[1:]) + np.log(kk_edges[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e411d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# effective z probed \n",
    "z_eff = 0.36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2761e4f1",
   "metadata": {},
   "source": [
    "### Get fiducial cosmology at the specific $k,z$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec766989-268d-4074-9b5e-29ddd5d42927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T17:31:33.135239Z",
     "iopub.status.busy": "2025-05-14T17:31:33.120947Z",
     "iopub.status.idle": "2025-05-14T17:31:33.174678Z",
     "shell.execute_reply": "2025-05-14T17:31:33.172742Z",
     "shell.execute_reply.started": "2025-05-14T17:31:33.135112Z"
    }
   },
   "outputs": [],
   "source": [
    "# Planck 2018 LCDM cosmology with TT,TE,EE+lowE\n",
    "planck_params = dict(omega_b=0.02236, omega_c=0.1202, ln10e10As=3.045, n_s=0.9649, H0=67.27)\n",
    "params = dict(\n",
    "    A_s=np.exp(planck_params['ln10e10As']) * 1e-10,\n",
    "    Omega_c=planck_params['omega_c'] / (planck_params['H0'] / 100.)**2,\n",
    "    Omega_b=planck_params['omega_b'] / (planck_params['H0'] / 100.)**2,\n",
    "    h=planck_params['H0'] / 100.,\n",
    "    n_s=planck_params['n_s'],\n",
    "    m_nu=[0.06, 0., 0.],\n",
    "    Neff=3.046)\n",
    "\n",
    "# Cosmological model\n",
    "cosmo = pyccl.Cosmology(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fadbe25d-cb9a-4cb7-8719-cc059855bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fiducial nonlinear matter power spectrum to compare to \n",
    "pk_nl_kz = pyccl.nonlin_matter_power(cosmo, kk, z_eff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011cc021",
   "metadata": {},
   "source": [
    "### Get $\\alpha(k)$ means and covariance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d939627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chain(fname):\n",
    "    return (np.vstack(np.load(fname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7d4729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_chain = load_chain('../chains/DES_nk24_sample_smoothness0.3_systTrue_ccovTrue.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e984e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_means = alpha_chain.mean(axis=0)\n",
    "alpha_covmat = np.cov(alpha_chain, rowvar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e517a5",
   "metadata": {},
   "source": [
    "### Truncate all vectors and matrices to the constrained region \n",
    "\n",
    "This is done by hand based on reproducing Fig. 2 from the paper. For the specific example here, the truncation is `[7:-9]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "729e3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk_trunc = kk[7:-9]\n",
    "alpha_trunc = alpha_means[7:-9]\n",
    "acov_trunc = alpha_covmat[7:-9, 7:-9]\n",
    "pk_nl_kz_trunc = pk_nl_kz[7:-9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c43fd",
   "metadata": {},
   "source": [
    "Invert the covariance matrix to save time during likelihood computations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cbcaff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_icov_trunc = np.linalg.inv(acov_trunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70419154",
   "metadata": {},
   "source": [
    "### Save components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1249139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./data/cls2pk/example', \n",
    "         kk=kk_trunc, z_eff=z_eff, \n",
    "         pk_fid=pk_nl_kz_trunc, \n",
    "         alpha=alpha_trunc, \n",
    "         aicov=a_icov_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509f670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
